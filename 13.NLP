Create a neural network for the given ‘housepricedata.csv’ to predict the whether price of
the house is above or below median value or not.
===============================
import tensorflow as tf
import keras
import pandas
import sklearn
import pandas as pd
df = pd.read_csv('housepricedata.csv')
print(df.head())
dataset = df.values
X = dataset[:,0:10]
Y = dataset[:,10]
from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
X_scale = min_max_scaler.fit_transform(X)
print(X_scale)
#Spliting the data for training, testing and validation
from sklearn.model_selection import train_test_split
X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale,
Y, test_size=0.3)
X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test,
Y_val_and_test, test_size=0.5)
#Trains the neural network with Keras
from keras.models import Sequential
from keras.layers import Dense

model = Sequential([
Dense(32, activation='relu', input_shape=(10,)), Dense(32,
activation='relu'),
Dense(1, activation='sigmoid'),
])
model.compile(optimizer='sgd', loss='binary_crossentropy',
metrics=['accuracy'])
hist = model.fit(X_train, Y_train, batch_size=32, epochs=100,
validation_data=(X_val, Y_val))
#Evaluate the model
print("\nAccuracy:",model.evaluate(X_test, Y_test)[1])
import matplotlib.pyplot as plt
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()


  output
-------------------
C:\Users\mlm\PycharmProjects\pythonProject1\.venv\Scripts\python.exe "C:\Users\mlm\PycharmProjects\BIBIN\13.neural network.py" 
2024-10-30 01:20:56.043387: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-10-30 01:20:58.084119: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
   LotArea  OverallQual  OverallCond  ...  Fireplaces  GarageArea  AboveMedianPrice
0     8450            7            5  ...           0         548                 1
1     9600            6            8  ...           1         460                 1
2    11250            7            5  ...           1         608                 1
3     9550            7            5  ...           1         642                 0
4    14260            8            5  ...           1         836                 1

[5 rows x 11 columns]
[[0.0334198  0.66666667 0.5        ... 0.5        0.         0.3864598 ]
 [0.03879502 0.55555556 0.875      ... 0.33333333 0.33333333 0.32440056]
 [0.04650728 0.66666667 0.5        ... 0.33333333 0.33333333 0.42877292]
 ...
 [0.03618687 0.66666667 1.         ... 0.58333333 0.66666667 0.17771509]
 [0.03934189 0.44444444 0.625      ... 0.25       0.         0.16925247]
 [0.04037019 0.44444444 0.625      ... 0.33333333 0.         0.19464034]]
C:\Users\mlm\PycharmProjects\pythonProject1\.venv\Lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2024-10-30 01:21:07.975770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.4872 - loss: 0.7055 - val_accuracy: 0.4475 - val_loss: 0.6954
Epoch 2/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.4844 - loss: 0.6936 - val_accuracy: 0.6393 - val_loss: 0.6856
Epoch 3/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6272 - loss: 0.6857 - val_accuracy: 0.6758 - val_loss: 0.6784
Epoch 4/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.6695 - loss: 0.6797 - val_accuracy: 0.7397 - val_loss: 0.6716
Epoch 5/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7342 - loss: 0.6711 - val_accuracy: 0.7306 - val_loss: 0.6649
Epoch 6/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7713 - loss: 0.6636 - val_accuracy: 0.7626 - val_loss: 0.6596
Epoch 7/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7636 - loss: 0.6580 - val_accuracy: 0.7717 - val_loss: 0.6543
Epoch 8/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7481 - loss: 0.6570 - val_accuracy: 0.7717 - val_loss: 0.6487
Epoch 9/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7810 - loss: 0.6514 - val_accuracy: 0.7671 - val_loss: 0.6425
Epoch 10/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7935 - loss: 0.6438 - val_accuracy: 0.8037 - val_loss: 0.6345
Epoch 11/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8035 - loss: 0.6368 - val_accuracy: 0.8219 - val_loss: 0.6266
Epoch 12/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8262 - loss: 0.6285 - val_accuracy: 0.8402 - val_loss: 0.6196
Epoch 13/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8197 - loss: 0.6224 - val_accuracy: 0.8311 - val_loss: 0.6129
Epoch 14/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8164 - loss: 0.6166 - val_accuracy: 0.8311 - val_loss: 0.6061
Epoch 15/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8085 - loss: 0.6139 - val_accuracy: 0.8447 - val_loss: 0.5989
Epoch 16/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8257 - loss: 0.6042 - val_accuracy: 0.8356 - val_loss: 0.5915
Epoch 17/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8313 - loss: 0.5938 - val_accuracy: 0.8356 - val_loss: 0.5838
Epoch 18/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8644 - loss: 0.5784 - val_accuracy: 0.8356 - val_loss: 0.5762
Epoch 19/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8328 - loss: 0.5783 - val_accuracy: 0.8402 - val_loss: 0.5677
Epoch 20/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8166 - loss: 0.5741 - val_accuracy: 0.8356 - val_loss: 0.5592
Epoch 21/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8512 - loss: 0.5565 - val_accuracy: 0.8402 - val_loss: 0.5498
Epoch 22/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8383 - loss: 0.5518 - val_accuracy: 0.8402 - val_loss: 0.5407
Epoch 23/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8486 - loss: 0.5397 - val_accuracy: 0.8402 - val_loss: 0.5309
Epoch 24/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8425 - loss: 0.5331 - val_accuracy: 0.8402 - val_loss: 0.5210
Epoch 25/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8418 - loss: 0.5287 - val_accuracy: 0.8493 - val_loss: 0.5109
Epoch 26/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8338 - loss: 0.5174 - val_accuracy: 0.8493 - val_loss: 0.5007
Epoch 27/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8478 - loss: 0.5051 - val_accuracy: 0.8493 - val_loss: 0.4907
Epoch 28/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8420 - loss: 0.4970 - val_accuracy: 0.8630 - val_loss: 0.4801
Epoch 29/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8588 - loss: 0.4834 - val_accuracy: 0.8584 - val_loss: 0.4700
Epoch 30/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8478 - loss: 0.4744 - val_accuracy: 0.8630 - val_loss: 0.4598
Epoch 31/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8501 - loss: 0.4677 - val_accuracy: 0.8630 - val_loss: 0.4499
Epoch 32/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8608 - loss: 0.4478 - val_accuracy: 0.8630 - val_loss: 0.4401
Epoch 33/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8607 - loss: 0.4528 - val_accuracy: 0.8676 - val_loss: 0.4307
Epoch 34/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8688 - loss: 0.4405 - val_accuracy: 0.8676 - val_loss: 0.4215
Epoch 35/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8558 - loss: 0.4346 - val_accuracy: 0.8676 - val_loss: 0.4127
Epoch 36/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8849 - loss: 0.4119 - val_accuracy: 0.8584 - val_loss: 0.4041
Epoch 37/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8626 - loss: 0.4135 - val_accuracy: 0.8676 - val_loss: 0.3956
Epoch 38/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8769 - loss: 0.3989 - val_accuracy: 0.8539 - val_loss: 0.3879
Epoch 39/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8775 - loss: 0.3923 - val_accuracy: 0.8584 - val_loss: 0.3804
Epoch 40/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8793 - loss: 0.3867 - val_accuracy: 0.8721 - val_loss: 0.3733
Epoch 41/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8803 - loss: 0.3982 - val_accuracy: 0.8721 - val_loss: 0.3668
Epoch 42/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8578 - loss: 0.3893 - val_accuracy: 0.8630 - val_loss: 0.3593
Epoch 43/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8690 - loss: 0.3851 - val_accuracy: 0.8813 - val_loss: 0.3530
Epoch 44/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8587 - loss: 0.3765 - val_accuracy: 0.8767 - val_loss: 0.3471
Epoch 45/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8510 - loss: 0.3787 - val_accuracy: 0.8676 - val_loss: 0.3416
Epoch 46/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8796 - loss: 0.3575 - val_accuracy: 0.8767 - val_loss: 0.3360
Epoch 47/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8879 - loss: 0.3479 - val_accuracy: 0.8813 - val_loss: 0.3310
Epoch 48/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8671 - loss: 0.3627 - val_accuracy: 0.8767 - val_loss: 0.3262
Epoch 49/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8671 - loss: 0.3587 - val_accuracy: 0.8813 - val_loss: 0.3218
Epoch 50/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8601 - loss: 0.3517 - val_accuracy: 0.8858 - val_loss: 0.3172
Epoch 51/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8682 - loss: 0.3435 - val_accuracy: 0.8858 - val_loss: 0.3133
Epoch 52/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8657 - loss: 0.3464 - val_accuracy: 0.8858 - val_loss: 0.3092
Epoch 53/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8666 - loss: 0.3408 - val_accuracy: 0.8904 - val_loss: 0.3055
Epoch 54/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8795 - loss: 0.3215 - val_accuracy: 0.8813 - val_loss: 0.3028
Epoch 55/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8810 - loss: 0.3253 - val_accuracy: 0.8858 - val_loss: 0.2986
Epoch 56/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8787 - loss: 0.3021 - val_accuracy: 0.8858 - val_loss: 0.2961
Epoch 57/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8774 - loss: 0.3104 - val_accuracy: 0.8904 - val_loss: 0.2929
Epoch 58/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8766 - loss: 0.3181 - val_accuracy: 0.8904 - val_loss: 0.2896
Epoch 59/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8732 - loss: 0.3130 - val_accuracy: 0.8950 - val_loss: 0.2869
Epoch 60/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8638 - loss: 0.3345 - val_accuracy: 0.8950 - val_loss: 0.2845
Epoch 61/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8715 - loss: 0.3154 - val_accuracy: 0.8950 - val_loss: 0.2823
Epoch 62/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8511 - loss: 0.3457 - val_accuracy: 0.8995 - val_loss: 0.2795
Epoch 63/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8806 - loss: 0.3093 - val_accuracy: 0.8950 - val_loss: 0.2776
Epoch 64/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8680 - loss: 0.3224 - val_accuracy: 0.8995 - val_loss: 0.2751
Epoch 65/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8666 - loss: 0.3069 - val_accuracy: 0.8904 - val_loss: 0.2754
Epoch 66/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8779 - loss: 0.3070 - val_accuracy: 0.8950 - val_loss: 0.2710
Epoch 67/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.3028 - val_accuracy: 0.8995 - val_loss: 0.2691
Epoch 68/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8707 - loss: 0.3047 - val_accuracy: 0.8950 - val_loss: 0.2689
Epoch 69/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8713 - loss: 0.3190 - val_accuracy: 0.9041 - val_loss: 0.2656
Epoch 70/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8836 - loss: 0.2861 - val_accuracy: 0.8995 - val_loss: 0.2642
Epoch 71/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8716 - loss: 0.3081 - val_accuracy: 0.8995 - val_loss: 0.2633
Epoch 72/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8733 - loss: 0.2942 - val_accuracy: 0.9041 - val_loss: 0.2610
Epoch 73/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8803 - loss: 0.2972 - val_accuracy: 0.8904 - val_loss: 0.2597
Epoch 74/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8708 - loss: 0.3101 - val_accuracy: 0.8995 - val_loss: 0.2584
Epoch 75/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8795 - loss: 0.2887 - val_accuracy: 0.8950 - val_loss: 0.2565
Epoch 76/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8769 - loss: 0.2908 - val_accuracy: 0.9041 - val_loss: 0.2555
Epoch 77/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8876 - loss: 0.2875 - val_accuracy: 0.8995 - val_loss: 0.2539
Epoch 78/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8652 - loss: 0.3191 - val_accuracy: 0.8950 - val_loss: 0.2538
Epoch 79/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8692 - loss: 0.2934 - val_accuracy: 0.8995 - val_loss: 0.2525
Epoch 80/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8719 - loss: 0.3022 - val_accuracy: 0.8995 - val_loss: 0.2509
Epoch 81/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8927 - loss: 0.2785 - val_accuracy: 0.8904 - val_loss: 0.2493
Epoch 82/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8734 - loss: 0.2949 - val_accuracy: 0.8904 - val_loss: 0.2482
Epoch 83/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8877 - loss: 0.2994 - val_accuracy: 0.8904 - val_loss: 0.2472
Epoch 84/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8845 - loss: 0.2857 - val_accuracy: 0.8950 - val_loss: 0.2467
Epoch 85/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8808 - loss: 0.2884 - val_accuracy: 0.8950 - val_loss: 0.2457
Epoch 86/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9029 - loss: 0.2646 - val_accuracy: 0.8950 - val_loss: 0.2442
Epoch 87/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8758 - loss: 0.2825 - val_accuracy: 0.8904 - val_loss: 0.2438
Epoch 88/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8724 - loss: 0.2945 - val_accuracy: 0.9041 - val_loss: 0.2432
Epoch 89/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8951 - loss: 0.2669 - val_accuracy: 0.8904 - val_loss: 0.2415
Epoch 90/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8789 - loss: 0.2875 - val_accuracy: 0.8904 - val_loss: 0.2407
Epoch 91/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8850 - loss: 0.2840 - val_accuracy: 0.8904 - val_loss: 0.2400
Epoch 92/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8798 - loss: 0.2870 - val_accuracy: 0.8995 - val_loss: 0.2397
Epoch 93/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8784 - loss: 0.2801 - val_accuracy: 0.8995 - val_loss: 0.2385
Epoch 94/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8815 - loss: 0.2849 - val_accuracy: 0.9041 - val_loss: 0.2418
Epoch 95/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8806 - loss: 0.2703 - val_accuracy: 0.8995 - val_loss: 0.2370
Epoch 96/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8830 - loss: 0.2914 - val_accuracy: 0.8995 - val_loss: 0.2367
Epoch 97/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.8875 - loss: 0.2635 - val_accuracy: 0.8995 - val_loss: 0.2357
Epoch 98/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8801 - loss: 0.2814 - val_accuracy: 0.8995 - val_loss: 0.2360
Epoch 99/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8894 - loss: 0.2935 - val_accuracy: 0.8858 - val_loss: 0.2341
Epoch 100/100
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8905 - loss: 0.2772 - val_accuracy: 0.8995 - val_loss: 0.2338
7/7 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8938 - loss: 0.2772 

Accuracy: 0.8949771523475647

Process finished with exit code 0


output is given as 13.pmg
